# app.py

import streamlit as st
import numpy as np
from st_pages import add_page_title, hide_pages
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from modules.data_cleaning import clean_data
from modules.analysis import auto_explore_data, generate_plots_automatically
from modules.ai_insight import generate_ai_insight
import gc  # æ·»åŠ åœ¨å…¶ä»– import è¯­å¥æ—è¾¹

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å¾®é£è½»è¯­BreeCho",
    page_icon="ğŸ’­",
    layout="wide",
    initial_sidebar_state="auto",
)

# éšè—Streamlité»˜è®¤å…ƒç´ 
hide_streamlit_style = """
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    .css-1lsmgbg.egzxvld1 {visibility: hidden;}
    </style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

add_page_title(layout="wide")
hide_pages(["Thank you"])

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.family'] = ['SimHei']

def convert_df_for_analysis(df):
    """å°† DataFrame è½¬æ¢ä¸ºé€‚åˆ AI åˆ†æçš„æ ¼å¼"""
    df_converted = df.copy()
    
    # å°†æ—¶é—´æˆ³åˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²
    for col in df_converted.select_dtypes(include=['datetime64']).columns:
        df_converted[col] = df_converted[col].dt.strftime('%Y-%m-%d %H:%M:%S')
    
    return df_converted

def display_column_info(column_types: dict):
    """å±•ç¤ºåˆ—ç±»å‹ä¿¡æ¯"""
    col1, col2 = st.columns(2)
    
    with col1:
        if column_types["integer"]:
            st.write("**æ•´æ•°ç±»å‹åˆ—:**", ", ".join(column_types["integer"]))
        if column_types["float"]:
            st.write("**æµ®ç‚¹ç±»å‹åˆ—:**", ", ".join(column_types["float"]))
        if column_types["datetime"]:
            st.write("**æ—¶é—´ç±»å‹åˆ—:**", ", ".join(column_types["datetime"]))
    
    with col2:
        if column_types["categorical"]:
            st.write("**åˆ†ç±»ç±»å‹åˆ—:**", ", ".join(column_types["categorical"]))
        if column_types["high_cardinality"]:
            st.write("**é«˜åŸºæ•°åˆ†ç±»åˆ—** (>20ä¸ªä¸åŒå€¼):", ", ".join(column_types["high_cardinality"]))

def main():
    # åˆå§‹åŒ– session_state å˜é‡
    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    if 'analysis_data' not in st.session_state:
        st.session_state.analysis_data = {
            "distribution_stats": {},
            "correlation_stats": {},
            "groupby_stats": {},
            "timeseries_stats": {}
        }
    if 'df_cleaned' not in st.session_state:
        st.session_state.df_cleaned = None
    if 'explore_result' not in st.session_state:
        st.session_state.explore_result = None
    if 'figs' not in st.session_state:
        st.session_state.figs = []
    if 'current_data_source' not in st.session_state:
        st.session_state.current_data_source = None
    if 'current_file' not in st.session_state:
        st.session_state.current_file = None

    # st.title("Excelè‡ªåŠ¨åˆ†æå·¥å…·ï¼ˆDemoï¼‰")

    st.markdown("### åŠŸèƒ½ä½¿ç”¨è¯´æ˜")
    st.markdown("1. é€‰æ‹©æ•°æ®æ¥æºï¼šä½¿ç”¨ç¤ºä¾‹æ•°æ®æˆ–ä¸Šä¼ æ–‡ä»¶")
    st.markdown("2. ç‚¹å‡»`å¼€å§‹åˆ†æ`æŒ‰é’®ï¼Œç­‰å¾…æ•°æ®åˆ†æå®Œæˆ")
    st.markdown("3. æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„åˆ†æç»“æœï¼ŒåŒ…æ‹¬æ•°æ®æ¦‚è§ˆã€è‡ªåŠ¨åŒ–æ•°æ®åˆ†æã€å¯è§†åŒ–åˆ†æå’Œè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯")
    st.markdown("4. åŸºäºæ•°æ®çš„å‰3600è¡Œè‡ªåŠ¨ç”Ÿæˆçš„æœ€å¤š30ä¸ªå›¾è¡¨")
    st.markdown("5. å±•å¼€å„ä¸ªéƒ¨åˆ†æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯")
    st.markdown("6. ç”Ÿæˆ AI åˆ†ææŠ¥å‘Šè·å–æ™ºèƒ½åˆ†ææ´å¯Ÿ")
    with st.expander("åŠŸèƒ½è¯´æ˜",expanded=False):
        st.markdown("""
è¿™æ˜¯ä¸€ä¸ªåŸºäº Streamlit å¼€å‘çš„ Excel è‡ªåŠ¨åˆ†æå·¥å…·,ä¸»è¦åŠŸèƒ½åŒ…æ‹¬:

1. æ•°æ®å¯¼å…¥åŠŸèƒ½
- æ”¯æŒç¤ºä¾‹æ•°æ®å’Œç”¨æˆ·ä¸Šä¼ çš„ Excel/CSV æ–‡ä»¶
- è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹å¹¶è¿›è¡Œç›¸åº”çš„æ•°æ®è¯»å–
- å±•ç¤ºåŸå§‹æ•°æ®å’Œæ¸…æ´—åçš„æ•°æ®é¢„è§ˆ

2. excelæ•°æ®æ ¼å¼è¦æ±‚
- æ•°æ®è¡¨ä¸­ï¼Œç¬¬ä¸€è¡Œæ˜¯åˆ—å
- åˆ—åä¸èƒ½æœ‰é‡å¤
- åˆ—åä¸èƒ½æœ‰ç©ºå€¼
- æ•°æ®è¡¨ä¸­ï¼Œåªå¤„ç†å‰2000è¡Œæ•°æ®
- æ•°æ®è¡¨ä¸­ï¼Œåªå¤„ç†å‰3ä¸ªæ•°å€¼åˆ—
- æ•°æ®è¡¨ä¸­ï¼Œåªå¤„ç†å‰1ä¸ªåˆ†ç±»åˆ—

3. æ•°æ®æ¦‚è§ˆåˆ†æ
- æ˜¾ç¤ºæ•°æ®è¡Œæ•°ã€åˆ—æ•°ã€ç¼ºå¤±å€¼æƒ…å†µç­‰åŸºæœ¬ä¿¡æ¯
- è‡ªåŠ¨è¯†åˆ«å¹¶å±•ç¤ºä¸åŒç±»å‹çš„åˆ—(æ•°å€¼ã€åˆ†ç±»ã€æ—¶é—´ç­‰)
- æä¾›æ•°æ®ç»“æ„çš„è¯¦ç»†åˆ†æ

4. è‡ªåŠ¨åŒ–æ•°æ®åˆ†æ
- ç”Ÿæˆæ¨èçš„å¯è§†åŒ–å›¾è¡¨
- æä¾›ç»Ÿè®¡åˆ†æå»ºè®®
- å±•ç¤ºæè¿°æ€§ç»Ÿè®¡ä¿¡æ¯

5. å¯è§†åŒ–åˆ†æ
- `åˆ†å¸ƒåˆ†æ`:ç›´æ–¹å›¾ã€ç®±çº¿å›¾ã€å°æç´å›¾ã€æŸ±çŠ¶å›¾ç­‰
- `ç›¸å…³æ€§åˆ†æ`:çƒ­åŠ›å›¾ã€æ•£ç‚¹å›¾ã€çŸ©é˜µå›¾ã€æˆå¯¹å›¾ç­‰
- `åˆ†ç±»åˆ†æ`:åˆ†ç»„ç®±çº¿å›¾ã€è®¡æ•°å›¾ã€åˆ†ç±»æŸ±çŠ¶å›¾ç­‰
- `æ—¶é—´åºåˆ—åˆ†æ`:è¶‹åŠ¿å›¾ã€å­£èŠ‚æ€§åˆ†è§£å›¾ç­‰

6. è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
- `åˆ†å¸ƒç»Ÿè®¡`:å‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®ç­‰
- `ç›¸å…³æ€§åˆ†æ`:å˜é‡é—´çš„ç›¸å…³ç³»æ•°
- `åˆ†ç»„ç»Ÿè®¡`:å„ç»„çš„ç»Ÿè®¡ç‰¹å¾
- `æ—¶é—´åºåˆ—ç‰¹å¾`:è¶‹åŠ¿ã€å­£èŠ‚æ€§åˆ†æ

7. AI æ´å¯Ÿ
- åŸºäºæ•°æ®è‡ªåŠ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š
- æä¾›æ•°æ®ç‰¹å¾çš„æ™ºèƒ½è§£è¯»

ä½¿ç”¨æ–¹æ³•:
1. é€‰æ‹©æ•°æ®æ¥æº(ç¤ºä¾‹æ•°æ®æˆ–ä¸Šä¼ æ–‡ä»¶)
2. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
3. æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„åˆ†æç»“æœ
4. å¯å±•å¼€å„ä¸ªéƒ¨åˆ†æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
5. ç‚¹å‡»"ç»˜åˆ¶å›¾è¡¨"æŒ‰é’®è·å–è‡ªåŠ¨ç”Ÿæˆçš„å›¾è¡¨
6. ç‚¹å‡»"ç”Ÿæˆ AI åˆ†ææŠ¥å‘Š"è·å–æ™ºèƒ½åˆ†ææ´å¯Ÿ
            """)
    # é€‰æ‹©æ•°æ®æ¥æº
    data_source = st.radio("è¯·é€‰æ‹©æ•°æ®æ¥æºï¼š", ("ä½¿ç”¨ç¤ºä¾‹æ•°æ®", "ä¸Šä¼ æ–‡ä»¶"))

    # æ£€æŸ¥æ•°æ®æºæ˜¯å¦æ”¹å˜
    if data_source != st.session_state.current_data_source:
        st.session_state.clear()
        st.session_state.current_data_source = data_source
        st.rerun()

    if data_source == "ä½¿ç”¨ç¤ºä¾‹æ•°æ®":
        st.info("å½“å‰ä½¿ç”¨ç¤ºä¾‹æ•°æ®")
        try:
            df = pd.read_csv('/opt/stapp/data/housing.csv')
        except Exception as e:
            st.error(f"ç¤ºä¾‹æ•°æ®è¯»å–å¤±è´¥: {str(e)}")
            return
    else:
        # æ¸…é™¤ä¹‹å‰çš„ä¸Šä¼ æ–‡ä»¶
        if 'uploaded_file_name' not in st.session_state:
            st.session_state.uploaded_file_name = None

        uploaded_file = st.file_uploader(
            "é€‰æ‹©ä¸€ä¸ªExcelæˆ–CSVæ–‡ä»¶", 
            type=["xlsx", "xls", "csv"],
            key="file_uploader"
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–°æ–‡ä»¶ä¸Šä¼ 
        if uploaded_file is not None:
            if st.session_state.uploaded_file_name != uploaded_file.name:
                # æ–°æ–‡ä»¶ä¸Šä¼ ï¼Œæ¸…é™¤ä¹‹å‰çš„åˆ†æç»“æœ
                st.session_state.clear()
                st.session_state.current_data_source = data_source
                st.session_state.uploaded_file_name = uploaded_file.name
                # st.rerun()  # ç«‹å³é‡æ–°è¿è¡Œï¼Œç¡®ä¿çŠ¶æ€è¢«æ¸…é™¤
                
            try:
                file_extension = uploaded_file.name.split('.')[-1].lower()
                
                with st.spinner("æ­£åœ¨åŠ è½½æ•°æ®..."):
                    if file_extension == 'csv':
                        df = pd.read_csv(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file, sheet_name=0)
                st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
                return
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ–‡ä»¶å†è¿›è¡Œåç»­æ“ä½œã€‚")
            return

    if 'analysis_complete' not in st.session_state:
        st.session_state.analysis_complete = False
    
    if not st.session_state.analysis_complete:
        # æ·»åŠ 3åˆ—ï¼Œæ¯åˆ—çš„åˆ—å®½æ¯”ä¾‹æ˜¯1ï¼š2ï¼š1
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True):  
                # # æ¸…ç†ä¼šè¯çŠ¶æ€ä¸­çš„å¯¹è±¡
                # # æ¸…ç†æ‰€æœ‰ä¼šè¯çŠ¶æ€
                # st.session_state.clear()

                # # å…³é—­æ‰€æœ‰æ‰“å¼€çš„matplotlibå›¾è¡¨
                # plt.close('all')

                # # å¼ºåˆ¶åƒåœ¾å›æ”¶
                # gc.collect()
                
                df_cleaned = clean_data(df)

                # # è‡ªåŠ¨åˆ†æ
                # with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):explore_result = auto_explore_data(df_cleaned)

                        
                # å¯è§†åŒ–éƒ¨åˆ†
                # st.subheader("ğŸ“ˆ æ•°æ®åˆ†æ")
                with st.spinner("æ­£åœ¨åˆ†ææ•°æ®ã€ç”Ÿæˆå›¾è¡¨..."):
                    explore_result = auto_explore_data(df_cleaned)
                    figs, analysis_data = generate_plots_automatically(
                                df_cleaned, 
                                explore_result["recommended_plots"]
                    )
                
                st.session_state.df_cleaned = df_cleaned
                st.session_state.explore_result = explore_result
                st.session_state.analysis_data = analysis_data
                st.session_state.figs = figs    
                st.session_state.analysis_complete = True
        
    else:
        st.info("ğŸ‘† ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹åˆ†ææ•°æ®")

    if st.session_state.analysis_complete == True:
        st.info("æ•°æ®åˆ†æå·²å®Œæˆ")
        col1, col2 = st.columns(2)
        with col1:
            st.subheader("åŸå§‹æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(), use_container_width=True)
        with col2:
            st.subheader("æ¸…æ´—åæ•°æ®é¢„è§ˆ")
            st.dataframe(st.session_state.df_cleaned.head(), use_container_width=True)

        # è‡ªåŠ¨åˆ†æ
        st.subheader("ğŸ“Š æ•°æ®æ¦‚è§ˆ")
        overview = st.session_state.explore_result["data_overview"]
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("æ€»è¡Œæ•°", overview["rows"])
        with col2:
            st.metric("æ€»åˆ—æ•°", overview["cols"])
        with col3:
            missing_cols = sum(1 for v in overview["missing_counts"].values() if v > 0)
            st.metric("å«ç¼ºå¤±å€¼çš„åˆ—æ•°", missing_cols)

        # åˆ—ç±»å‹ä¿¡æ¯
        st.subheader("ğŸ“‘ æ•°æ®ç»“æ„åˆ†æ")
        display_column_info(st.session_state.explore_result["column_types"])

        # å¢åŠ dataframeå±•ç¤ºæ‰€æœ‰æ•°æ® é»˜è®¤æŠ˜å  å¢åŠ æ•°æ®åˆ†å¸ƒå±•ç¤º
        st.subheader("ğŸ“Š æ•°æ®")
        st.dataframe(st.session_state.df_cleaned, use_container_width=True, hide_index=True)
                # åˆ†æå»ºè®®
        st.subheader("ğŸ” åˆ†æå»ºè®® &ğŸ“Š æ•°æ®åˆ†å¸ƒ")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.write("**æ¨èçš„å¯è§†åŒ–:**")
            for plot in st.session_state.explore_result["recommended_plots"]:
                st.write(f"- {plot}")
        with col2:
            st.write("**æ¨èçš„ç»Ÿè®¡åˆ†æ:**")
            for stat in st.session_state.explore_result["recommended_stats"]:
                st.write(f"- {stat}")
        with col3:
            st.write("**æ•°æ®æè¿°æ€§ç»Ÿè®¡:**")
            st.dataframe(st.session_state.df_cleaned.describe())

            # ç¼ºå¤±å€¼è¯¦æƒ…
            if missing_cols > 0:
                with st.expander("æŸ¥çœ‹ç¼ºå¤±å€¼è¯¦æƒ…"):
                    missing_df = pd.DataFrame.from_dict(
                        overview["missing_counts"], 
                        orient='index',
                        columns=['ç¼ºå¤±å€¼æ•°é‡']
                    )
                    missing_df = missing_df[missing_df['ç¼ºå¤±å€¼æ•°é‡'] > 0]
                    st.dataframe(missing_df)
           

    if  st.session_state.analysis_complete:
            # æ˜¾ç¤ºå…³é”®åˆ†ææ•°æ®
        with st.expander("ğŸ“Š æŸ¥çœ‹è¯¦ç»†åˆ†ææ•°æ®",expanded=False):
            # åˆ†å¸ƒç»Ÿè®¡
            cols1 = st.columns(4)
            if st.session_state.analysis_data["distribution_stats"]:
                with cols1[0]:  
                    st.subheader("åˆ†å¸ƒç»Ÿè®¡")
                    for col, stats in st.session_state.analysis_data["distribution_stats"].items():
                        st.write(f"**{col}** çš„ç»Ÿè®¡æ•°æ®:")
                        st.write(f"- å‡å€¼: {stats['mean']:.2f}")
                        st.write(f"- ä¸­ä½æ•°: {stats['median']:.2f}")
                        st.write(f"- æ ‡å‡†å·®: {stats['std']:.2f}")
                        st.write(f"- ååº¦: {stats['skew']:.2f}")
                        st.write(f"- å³°åº¦: {stats['kurtosis']:.2f}")
            
            # ç›¸å…³æ€§åˆ†æ
            if st.session_state.analysis_data["correlation_stats"]:
                with cols1[1]:
                    st.subheader("æ˜¾è‘—ç›¸å…³æ€§")
                    for corr in st.session_state.analysis_data["correlation_stats"].get("high_correlations", []):
                        st.write(
                            f"- {corr['var1']} ä¸ {corr['var2']} çš„ç›¸å…³ç³»æ•°: "
                            f"{corr['correlation']:.2f}"
                        )
            
            # åˆ†ç»„åˆ†æ
            if st.session_state.analysis_data["groupby_stats"]:
                with cols1[2]:
                    st.subheader("åˆ†ç»„ç»Ÿè®¡")
                    for key, stats in st.session_state.analysis_data["groupby_stats"].items():
                        st.write(f"**{key}** çš„åˆ†ç»„åˆ†æ:")
                    st.write("ç»„é—´å·®å¼‚æ˜¾è‘—æ€§æ£€éªŒ:")
                    p_value = stats["anova_test"]["p_value"]
                    st.write(
                        f"- På€¼: {p_value:.4f} "
                        f"({'æ˜¾è‘—' if p_value < 0.05 else 'ä¸æ˜¾è‘—'})"
                    )
                    st.write("å„ç»„ç»Ÿè®¡æ•°æ®:")
                    st.json(stats["group_stats"])
            
            # æ—¶é—´åºåˆ—åˆ†æ
            if st.session_state.analysis_data["timeseries_stats"]:
                with cols1[3]:
                    st.subheader("æ—¶é—´åºåˆ—åˆ†æ")
                    for col, stats in st.session_state.analysis_data["timeseries_stats"].items():
                        st.write(f"**{col}** çš„æ—¶é—´åºåˆ—ç‰¹å¾:")
                        st.write(f"- æ€»ä½“å˜åŒ–: {stats['trend']['change_pct']:.2f}%")
                        st.write(f"- æ³¢åŠ¨æ€§(æ ‡å‡†å·®): {stats['volatility']:.2f}")
                    if stats['seasonality']:
                        st.write("- æœˆåº¦å‡å€¼è¶‹åŠ¿:")
                        st.line_chart(pd.Series(stats['seasonality']['monthly_mean']))

        # å¯è§†åŒ–éƒ¨åˆ†
        if st.session_state.figs:
            st.subheader("ğŸ“ˆ å¯è§†åŒ–åˆ†æ")
            st.markdown(f"""
å…±æœ‰ {len(st.session_state.figs)} ä¸ªå›¾è¡¨ï¼Œç»˜åˆ¶å›¾è¡¨æ—¶è¯·è€å¿ƒç­‰å¾…
                        """)
            # if st.button("ğŸš€ç‚¹å‡»ç»˜åˆ¶å›¾è¡¨"):
                # plt.close('all')  # å…³é—­æ‰€æœ‰æœªä½¿ç”¨çš„å›¾è¡¨
                # gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
            with st.spinner("æ­£åœ¨ç”Ÿæˆå›¾è¡¨..."): 
                # åœ¨ç”Ÿæˆå›¾è¡¨ä¹‹å‰æ·»åŠ 
                plt.rcParams['figure.max_open_warning'] = 100  # å¢åŠ æœ€å¤§å›¾è¡¨æ•°é‡é™åˆ¶
                plt.rcParams['agg.path.chunksize'] = 10000  # é™ä½è·¯å¾„å¤æ‚åº¦

                # ä½¿ç”¨tabsæ¥ç»„ç»‡ä¸åŒç±»å‹çš„å›¾è¡¨
                viz_types = {
                    "åˆ†å¸ƒåˆ†æ": ["histogram", "distribution", "violin", "boxplot"],
                    "ç›¸å…³æ€§åˆ†æ": ["correlation", "scatter", "heatmap", "matrix", "pair"],
                    "åˆ†ç±»åˆ†æ": ["count", "bar", "category","grouped"],
                    "æ—¶é—´åºåˆ—": ["time", "series", "decompose"]
                }
                
                # å¯¹å›¾è¡¨è¿›è¡Œåˆ†ç±»
                categorized_figs = {k: [] for k in viz_types.keys()}
                
                for fig in st.session_state.figs:
                    try:
                        if hasattr(fig, 'axes') and len(fig.axes) > 0:
                            # è·å–å›¾è¡¨æ ‡é¢˜
                            if hasattr(fig, 'texts') and fig.texts:
                                title = fig.texts[0].get_text().lower()
                            else:
                                title = fig.axes[0].get_title().lower()
                            
                            # å°†å›¾è¡¨åˆ†é…åˆ°å¯¹åº”ç±»åˆ«
                            for category, keywords in viz_types.items():
                                if any(keyword in title for keyword in keywords):
                                    # é™åˆ¶å›¾è¡¨å¤§å°
                                    fig.set_size_inches(10, 6)  # è®¾ç½®ç»Ÿä¸€çš„å›¾è¡¨å¤§å°
                                    fig.set_dpi(100)  # è®¾ç½®é€‚ä¸­çš„DPI
                                    categorized_figs[category].append(fig)
                                    break
                    except Exception as e:
                        st.warning(f"å¤„ç†å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                        continue
        
                # åˆ›å»ºæ ‡ç­¾é¡µå¹¶æ˜¾ç¤ºå›¾è¡¨
                tabs = st.tabs(list(viz_types.keys()))
                for tab, category in zip(tabs, viz_types.keys()):
                    with tab:
                        if categorized_figs[category]:
                            # ä½¿ç”¨åˆ—å¸ƒå±€æ˜¾ç¤ºå›¾è¡¨
                            cols = st.columns(2)  # æ¯è¡Œæ˜¾ç¤º2ä¸ªå›¾è¡¨
                            for i, fig in enumerate(categorized_figs[category]):
                                try:
                                    with cols[i % 2]:
                                        st.pyplot(fig)
                                except Exception as e:
                                    st.warning(f"æ˜¾ç¤ºå›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                                    continue
                        else:
                            st.info(f"æ²¡æœ‰{category}ç±»å‹çš„å›¾è¡¨")

        # åœ¨åˆ†ææ•°æ®å±•ç¤ºéƒ¨åˆ†æ·»åŠ æ–°çš„ç»Ÿè®¡ä¿¡æ¯å±•ç¤º
        if "distribution_stats" in st.session_state.analysis_data:
            with st.expander("ğŸ“Š åˆ†å¸ƒç»Ÿè®¡è¯¦æƒ…",expanded=False):
                for col, stats in st.session_state.analysis_data["distribution_stats"].items():
                    st.write(f"**{col}** çš„ç»Ÿè®¡æ•°æ®:")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"- å‡å€¼: {stats['mean']:.2f}")
                        st.write(f"- ä¸­ä½æ•°: {stats['median']:.2f}")
                        st.write(f"- æ ‡å‡†å·®: {stats['std']:.2f}")
                    with col2:
                        st.write(f"- ååº¦: {stats['skew']:.2f}")
                        st.write(f"- å³°åº¦: {stats['kurtosis']:.2f}")

        # æ·»åŠ æ—¶é—´åºåˆ—åˆ†è§£ç»“æœå±•ç¤º
        if "timeseries_stats" in st.session_state.analysis_data:
            with st.expander("ğŸ“ˆ æ—¶é—´åºåˆ—åˆ†æè¯¦æƒ…",expanded=False):
                for col, stats in st.session_state.analysis_data["timeseries_stats"].items():
                    st.write(f"**{col}** çš„æ—¶é—´åºåˆ—ç‰¹å¾:")
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write("è¶‹åŠ¿åˆ†æ:")
                        st.write(f"- èµ·å§‹å€¼: {stats['trend']['start_value']:.2f}")
                        st.write(f"- ç»“æŸå€¼: {stats['trend']['end_value']:.2f}")
                        st.write(f"- å˜åŒ–ç‡: {stats['trend']['change_pct']:.2f}%")
                    with col2:
                        st.write("æ³¢åŠ¨æ€§åˆ†æ:")
                        st.write(f"- æ ‡å‡†å·®: {stats['volatility']:.2f}")
                        if stats.get('seasonality'):
                            st.write("å­£èŠ‚æ€§åˆ†æ:")
                            monthly_data = pd.Series(stats['seasonality']['monthly_mean'])
                            st.line_chart(monthly_data)

            # åœ¨æ˜¾ç¤ºåˆ†ææ•°æ®çš„éƒ¨åˆ†æ·»åŠ åˆ†ç»„åˆ†æç»“æœçš„å±•ç¤º
        if st.session_state.analysis_data.get("group_analysis"):
            st.subheader("ğŸ“Š åˆ†ç»„åˆ†æç»“æœ")
            for group_col, analysis in st.session_state.analysis_data["group_analysis"].items():
                with st.expander(f"æŸ¥çœ‹ {group_col} çš„åˆ†ç»„åˆ†æ",expanded=False):
                    # åŸºç¡€ç»Ÿè®¡
                    st.write("**åŸºç¡€ç»Ÿè®¡æŒ‡æ ‡**")
                    for metric, values in analysis["basic_stats"].items():
                        st.write(f"- {metric}:")
                        st.json(values)
                    
                    # é«˜çº§ç»Ÿè®¡
                    st.write("**é«˜çº§ç»Ÿè®¡åˆ†æ**")
                    for num_col, stats in analysis["advanced_stats"].items():
                        st.write(f"**{num_col}** çš„åˆ†æ:")
                        st.write("- å„ç»„å æ¯”:")
                        st.json(stats["proportions"])
                        if "growth_rates" in stats:
                            st.write("- å¢é•¿ç‡:")
                            st.json(stats["growth_rates"])
                    
                    # åˆ†å¸ƒåˆ†æ
                    st.write("**åˆ†å¸ƒåˆ†æ**")
                    for num_col, dist_stats in analysis["distribution_analysis"].items():
                        st.write(f"**{num_col}** çš„åˆ†å¸ƒ:")
                        st.write("- å››åˆ†ä½æ•°:")
                        st.json(dist_stats["quartiles"])
                        st.write("- å¼‚å¸¸å€¼æ•°é‡:")
                        st.json(dist_stats["outliers_count"])
                    

            # åœ¨æ˜¾ç¤ºåˆ†ææ•°æ®çš„éƒ¨åˆ†ä¿®æ”¹ç›¸å…³æ€§åˆ†æçš„å±•ç¤º
        if st.session_state.analysis_data["correlation_stats"]:
            with st.expander("ğŸ“Š ç›¸å…³æ€§åˆ†æè¯¦æƒ…",expanded=False):
                # åŸå§‹æ•°æ®ç›¸å…³æ€§
                st.write("**åŸå§‹æ•°æ®ç›¸å…³æ€§**")
                st.dataframe(
                    pd.DataFrame(st.session_state.analysis_data["correlation_stats"]["original"]["matrix"])
                )
                
                # å˜æ¢åçš„ç›¸å…³æ€§
                st.write("**æ•°æ®å˜æ¢åçš„ç›¸å…³æ€§**")
                for transform_type, transform_results in st.session_state.analysis_data["correlation_stats"]["transformed"].items():
                    st.write(f"*{transform_type.capitalize()} å˜æ¢åçš„ç›¸å…³æ€§*")
                    st.dataframe(pd.DataFrame(transform_results["matrix"]))
                    
                    if transform_results["high_correlations"]:
                        st.write(f"*{transform_type.capitalize()} å˜æ¢åçš„æ˜¾è‘—ç›¸å…³æ€§ (|r| > 0.5)*")
                        for corr in transform_results["high_correlations"]:
                            st.write(
                                f"- {corr['var1']} ä¸ {corr['var2']}: "
                                f"{corr['correlation']:.3f}"
                            )
                
                # æ˜¾è‘—ç›¸å…³æ€§å˜åŒ–
                st.write("**ç›¸å…³æ€§å˜åŒ–åˆ†æ**")
                
                if st.session_state.analysis_data["correlation_stats"]["significant_correlations"]["improved_by_transform"]:
                    st.write("*ç›¸å…³æ€§æ˜¾è‘—æé«˜çš„å˜é‡å¯¹:*")
                    for improved in st.session_state.analysis_data["correlation_stats"]["significant_correlations"]["improved_by_transform"]:
                        st.write(
                            f"- {improved['var1']} ä¸ {improved['var2']}: "
                            f"åŸå§‹ç›¸å…³æ€§ {improved['original_corr']:.3f} -> "
                            f"{improved['transform']}å˜æ¢å {improved['transformed_corr']:.3f}"
                        )
                
                if st.session_state.analysis_data["correlation_stats"]["significant_correlations"]["consistent_high"]:
                    st.write("*å§‹ç»ˆä¿æŒé«˜ç›¸å…³çš„å˜é‡å¯¹:*")
                    for consistent in st.session_state.analysis_data["correlation_stats"]["significant_correlations"]["consistent_high"]:
                        st.write(
                            f"- {consistent['var1']} ä¸ {consistent['var2']}: "
                            f"ç›¸å…³æ€§ä¿æŒåœ¨ {min(consistent['correlations'].values()):.3f} ä»¥ä¸Š"
                        )
                
        # AI æ´å¯Ÿ
        st.subheader("ğŸ¤– AI æ´å¯Ÿ")
        if st.session_state.analysis_complete == True:
            with st.spinner("AIæ­£åœ¨åˆ†ææ•°æ®..."):
                summary = generate_ai_insight(
                    st.session_state.df_cleaned, 
                    {"auto_explore": st.session_state.explore_result,
                    "auto_analysis": st.session_state.analysis_data
                    }
                )
                st.write(summary)
        
        

if __name__ == "__main__":
    main()

