import streamlit as st
from openai import OpenAI
from st_pages import add_page_title, hide_pages
# import tiktoken


st.set_page_config(
    page_title="å¾®é£è½»è¯­BreeCho",  # è‡ªå®šä¹‰é¡µé¢æ ‡é¢˜
    page_icon="ğŸ’­",  # å¯ä»¥æ˜¯ä¸€ä¸ªURLé“¾æ¥ï¼Œæˆ–è€…æ˜¯emojiè¡¨æƒ…ç¬¦å·
    layout="wide",  # é¡µé¢å¸ƒå±€: "centered" æˆ– "wide"
    initial_sidebar_state="collapsed",  # åˆå§‹ä¾§è¾¹æ çŠ¶æ€: "auto", "expanded", "collapsed"
)


# streamlit run GB500142021AO.py
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            .css-1lsmgbg.egzxvld1 {visibility: hidden;} /* This targets the Deploy button */
            </style>
            """

st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# # è‡ªå®šä¹‰CSSæ ·å¼ï¼Œä½¿ç”¨è‡ªå®šä¹‰å­—ä½“
# custom_css = """
# <style>
# @font-face {
#     font-family: 'LXGW WenKai GB';
#     src: url('LXGWWenKaiGB.ttf') format('truetype');
# }
# body {
#     font-family: 'LXGW WenKai GB', serif;
# }
# </style>
# """

# st.markdown(custom_css, unsafe_allow_html=True)

add_page_title(layout="wide")


API_BASE = "è¿™é‡Œæ˜¯base_url"
API_KEY = "è¿™é‡Œæ˜¯key"
client = OpenAI(
    api_key=API_KEY,
    base_url=API_BASE
)

# è®¾ç½®è¾“å…¥å’Œè¾“å‡ºçš„ tokens é™åˆ¶
INPUT_TOKENS_LIMIT = 512
OUTPUT_TOKENS_LIMIT = 2048
# st.title("ğŸ’¬ Chatbot")

if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—?"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# è®¡ç®—æ¶ˆæ¯çš„ tokens æ•°é‡çš„å‡½æ•°
# def count_tokens(message, model="yi-medium"):
#     encoding = tiktoken.encoding_for_model(model)
#     return len(encoding.encode(message))

if prompt := st.chat_input():
    # if not openai_api_key:
    #     st.info("Please add your OpenAI API key to continue.")
    #     st.stop()

    # client = OpenAI(api_key=openai_api_key)
        # è®¡ç®—è¾“å…¥æ¶ˆæ¯çš„ tokens æ•°é‡
    # input_tokens = count_tokens(prompt)
    
    # if input_tokens > INPUT_TOKENS_LIMIT:
    #     st.warning(f"è¾“å…¥æ¶ˆæ¯è¿‡é•¿ï¼Œè¯·é™åˆ¶åœ¨ {INPUT_TOKENS_LIMIT} ä¸ª tokens ä»¥å†…ã€‚")

    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    response = client.chat.completions.create(model="yi-medium", messages=st.session_state.messages, max_tokens=OUTPUT_TOKENS_LIMIT)
    msg = response.choices[0].message.content
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)