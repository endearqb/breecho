import streamlit as st
from openai import OpenAI
from st_pages import add_page_title, hide_pages
import time
# import tiktoken


st.set_page_config(
    page_title="å¾®é£è½»è¯­BreeCho",  # è‡ªå®šä¹‰é¡µé¢æ ‡é¢˜
    page_icon="ğŸ’­",  # å¯ä»¥æ˜¯ä¸€ä¸ªURLé“¾æ¥ï¼Œæˆ–è€…æ˜¯emojiè¡¨æƒ…ç¬¦å·
    layout="wide",  # é¡µé¢å¸ƒå±€: "centered" æˆ– "wide"
    initial_sidebar_state="collapsed",  # åˆå§‹ä¾§è¾¹æ çŠ¶æ€: "auto", "expanded", "collapsed"
)


# streamlit run GB500142021AO.py
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            .css-1lsmgbg.egzxvld1 {visibility: hidden;} /* This targets the Deploy button */
            </style>
            """

st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# # è‡ªå®šä¹‰CSSæ ·å¼ï¼Œä½¿ç”¨è‡ªå®šä¹‰å­—ä½“
# custom_css = """
# <style>
# @font-face {
#     font-family: 'LXGW WenKai GB';
#     src: url('LXGWWenKaiGB.ttf') format('truetype');
# }
# body {
#     font-family: 'LXGW WenKai GB', serif;
# }
# </style>
# """

# st.markdown(custom_css, unsafe_allow_html=True)

add_page_title(layout="wide")


API_BASE = "è¿™é‡Œæ˜¯base_url"
API_KEY = "è¿™é‡Œæ˜¯key"
client = OpenAI(
    api_key=API_KEY,
    base_url=API_BASE
)

# è®¾ç½®è¾“å…¥å’Œè¾“å‡ºçš„ tokens é™åˆ¶
INPUT_TOKENS_LIMIT = 512
OUTPUT_TOKENS_LIMIT = 2048
# st.title("ğŸ’¬ Chatbot")

# # Streamed response emulator
# def get_completion(prompt, model="yi-medium"):
#     messages = [
#         # {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¿»è¯‘ï¼Œä½ ä¼šæ ¹æ®ç”¨æˆ·çš„è¾“å…¥ç›´æ¥ç¿»è¯‘æˆè‹±æ–‡ã€‚"},
#         {"role": "user", "content": prompt}]
#     response = client.chat.completions.create(
#         model=model,
#         messages=messages,
#         temperature=0, # this is the degree of randomness of the model's output
#     )
#     return response.choices[0].message.content

def nicereader(prompt):
    prompt = f"""
    
    ä½ æ˜¯ä¸€ä¸ªæ•°å­¦é¢˜è¯»é¢˜å¤§å¸ˆï¼Œåœ¨åˆ¤æ–­é—®é¢˜è·Ÿé€»è¾‘æ¨ç†å’Œæ•°å­¦è®¡ç®—ç›¸å…³åï¼Œèƒ½å¤Ÿå°†æ•°å­¦é¢˜ä¸­çš„æ¡ä»¶åˆ†æ®µï¼Œå¹¶ä¸€ä¸ªä¸€ä¸ªæè¿°ä¸ºæ›´æ¸…æ™°çš„æ•°å­—ä¿¡æ¯ï¼Œåå¤æ€è€ƒï¼Œå°½å¯èƒ½è¡¥å……å®Œæ•´çš„ä¿¡æ¯ï¼Œä½¿æ•°å­¦é¢˜æ‹¥æœ‰æ›´æ˜ç¡®çš„æ•°å€¼å’Œæ•°å€¼å…³ç³»,åªéœ€è¦è½¬å†™å’Œåšç®€å•çš„ä¸€æ­¥è®¡ç®—ï¼Œä¸éœ€è¦è§£ç­”æ•°å­¦é¢˜ã€‚
    è½¬å†™ä¸¾ä¾‹ï¼š
    1.ç°åœ¨æ˜¯9æ—¶ï¼Œä¸€åˆ»é’Ÿåæˆ‘å°†å‡ºå‘-->ç°åœ¨æ˜¯9æ—¶ï¼Œ9æ—¶15åˆ†(9æ—¶+ä¸€åˆ»=9æ—¶15åˆ†)æˆ‘å°†å‡ºå‘
    2.æˆ‘ä»Šå¹´35å²ï¼Œæ˜¯æˆ‘å¥³å„¿å¹´é¾„çš„5å€-->æˆ‘ä»Šå¹´35å²ï¼Œæˆ‘å¥³å„¿å¹´é¾„7å²(35/5=7)
    3.æˆ‘å’Œå°ç‹ä¸€èµ·èµ°äº†40ç±³--> æˆ‘å’Œå°ç‹ä¸€èµ·èµ°äº†40ç±³(æˆ‘èµ°äº†40ç±³ï¼Œå°ç‹èµ°äº†40ç±³)
    4.å°ç‹å…ˆå‡ºå‘ï¼Œæˆ‘åå‡ºå‘ï¼Œæˆ‘åœ¨100ç±³å¤„è¿½ä¸Šäº†å°ç‹-->å°ç‹å…ˆå‡ºå‘ï¼Œæˆ‘åå‡ºå‘ï¼Œæˆ‘åœ¨100ç±³å¤„è¿½ä¸Šäº†å°ç‹(æˆ‘èµ°äº†100ç±³ï¼Œå°ç‹èµ°äº†100ç±³)
    5.æˆ‘å’Œå°ç‹é€Ÿåº¦ä¸€æ ·ï¼Œä»å®¶å‡ºå‘ä¸€èµ·èµ°äº†40ç±³ï¼Œç„¶åæˆ‘ç«‹åˆ»å›å®¶ï¼Œå°ç‹ç»§ç»­å¾€å‰èµ°äº†40ç±³-->æˆ‘å’Œå°ç‹é€Ÿåº¦ä¸€æ ·ï¼Œä»å®¶å‡ºå‘ä¸€èµ·èµ°äº†40ç±³(æˆ‘èµ°äº†40ç±³ï¼Œå°ç‹èµ°äº†40ç±³)ï¼Œç„¶åæˆ‘ç«‹åˆ»å›å®¶(æˆ‘å¾€å›èµ°äº†40ç±³)ï¼Œå°ç‹ç»§ç»­å¾€å‰èµ°äº†40ç±³
    
    è¿”å›è¦æ±‚ï¼šåªè¿”å›print()ä¸­çš„å…·ä½“å†…å®¹
    # æ­¥éª¤
    if {prompt} is not æ•°å­¦æˆ–è€…é€»è¾‘ç›¸å…³é—®é¢˜:
        print("è¯·å‘Šè¯‰æˆ‘æƒ³å’Œæˆ‘ä¸€èµ·åšçš„æ•°å­¦é¢˜")
    else:
        content=[] # è½¬å†™åçš„å†…å®¹
        print(content)

    
    """
    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model="deepseek-coder",
        messages=messages,
        temperature=0, 
    )
    return response.choices[0].message.content

def problem_solver(prompt):
    prompt = f"""
    # ä½ æ˜¯ä¸€ä¸ªæ•°å­¦é¢˜å­¦ä¹ ä¼™ä¼´ï¼Œä½ ä¸ç›´æ¥è®¡ç®—æ•°å­¦é¢˜çš„ç­”æ¡ˆï¼Œè€Œæ˜¯ä¸€æ­¥ä¸€æ­¥å¸®åŠ©æˆ‘è§£å‡ºæ•°å­¦é¢˜{prompt}

    """
    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model="deepseek-coder",
        messages=messages,
        temperature=0, 
    )
    
    return response.choices[0].message.content    


if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "assistant", "content": "æˆ‘æ˜¯ä¸€ä¸ªå°å­¦æ•°å­¦é¢˜åº”ç”¨é¢˜å­¦ä¹ ä¼™ä¼´ï¼Œè¯·å‘Šè¯‰æˆ‘ä½ æƒ³å­¦ä¹ çš„æ•°å­¦é¢˜å§"}]
    


for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# if "chat_history" not in st.session_state:
#     st.session_state.chat_history = []

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    # response = get_completion(prompt)
    msg = nicereader(prompt)
    st.session_state.messages.append({"role": "assistant", "content": msg})
    st.chat_message("assistant").write(msg)
    wait_msg = "è¯·ç¨ç­‰ç‰‡åˆ»ï¼Œæˆ‘æ­£åœ¨ä¸ºæ‚¨è§£ç­”æ•°å­¦é¢˜"
    st.session_state.messages.append({"role": "assistant", "content": wait_msg})
    st.chat_message("assistant").write(wait_msg)
    answer_path=problem_solver(msg)
    # responses = st.write_stream(msg)
    # Add assistant response to chat history
    # st.session_state.messages.append({"role": "assistant", "content": responses})
    st.session_state.messages.append({"role": "assistant", "content": answer_path})
    st.chat_message("assistant").write(answer_path)